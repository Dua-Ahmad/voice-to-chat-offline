ğŸ™ï¸ Offline Voice-to-Chat Web App

Full Offline Speech-to-Text (STT) + Text-to-Speech (TTS)
Built with Flask, OpenAI Whisper, and Coqui-TTS â€” wrapped in a clean, responsive browser interface.

ğŸ§  Overview

This project turns your local computer into a self-contained voice assistant interface.
It captures your voice through the browser, transcribes it with an offline Whisper model, and replies with realistic speech synthesized locally via Coqui TTS â€” without an internet connection.

âš™ï¸ Architecture
Browser (HTML/JS) â”€â–º Flask API â”€â–º Whisper STT (Python)
                â—„â”€â”€ Flask API â—„â”€â”€ Coqui TTS (Python)

Components
Layer	File	Purpose
Frontend UI	templates/index.html, static/script.js, static/style.css	Voice recording, playback, and display
Backend App	app.py	Flask server managing /transcribe and /speak routes
STT Module	stt_whisper.py	Uses OpenAI Whisper for offline speech-to-text
TTS Module	tts_coqui.py	Uses Coqui TTS for neural text-to-speech
Dependencies	requirements.txt	Python packages (Flask, TTS, Whisper, etc.)
Deployment	Dockerfile, commands-to-run.txt	Container build and run commands
ğŸ§© Model Details
ğŸ—£ï¸ Speech-to-Text (STT)
Feature	Description
Model	openai-whisper
File	stt_whisper.py

Architecture	Transformer-based encoder-decoder
Loaded size	small (â‰ˆ 500 MB)
Offline	âœ… Yes â€” runs locally via PyTorch
Function	transcribe_audio(path) loads the model once, processes .wav files, and returns clean text.

Example:

import whisper
model = whisper.load_model("small")
text = model.transcribe("sample.wav")["text"]


ğŸ“Œ You can swap small for base, medium, or large in stt_whisper.py depending on hardware.

ğŸ”Š Text-to-Speech (TTS)
Feature	Description
Model	tts_models/en/ljspeech/tacotron2-DDC
File	tts_coqui.py

Architecture	Tacotron 2 + DDC vocoder
Offline	âœ… Yes
Function	speak_text(text) generates a .wav file under /static/audio/.

Example:

from TTS.api import TTS
tts = TTS("tts_models/en/ljspeech/tacotron2-DDC")
tts.tts_to_file("Hello there!", "output.wav")


Alternative multilingual model:

TTS("tts_models/multilingual/multi-dataset/your_tts")

ğŸ§± Project Setup
1ï¸âƒ£ Clone repository
git clone https://gitlab.com/<your-username>/voice-to-chat-offline.git
cd voice-to-chat-offline

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt


Requirements include:

flask
sounddevice
simpleaudio
scipy
TTS
openai-whisper

3ï¸âƒ£ Run locally
python app.py


Then open: http://localhost:5000

ğŸ³ Run via Docker

Build and start the container:

docker build --no-cache -t voice-web-app .
docker run -it -p 5000:5000 voice-web-app


Open your browser at: http://localhost:5000

ğŸª„ Using the App

Open the web page.

Click ğŸ™ Record â€” speak a short phrase.

When you stop, Whisper transcribes it locally.

Click ğŸ”Š Speak â€” Coqui TTS generates and plays back audio of your text.

Everything happens offline; no API calls or cloud dependencies.

ğŸ§  Model Selection Guide
Goal	STT Model	TTS Model	Why
ğŸ’¨ Fast on CPU	Whisper tiny	Coqui DDC	Lightweight setup
ğŸ§ Accurate & clear	Whisper small	Coqui DDC	Balanced accuracy
ğŸ”Š Natural voice	Whisper small	Coqui YourTTS	Expressive multilingual
ğŸ–¥ GPU system	Whisper medium / large	Coqui Glow-TTS	Studio-quality
ğŸ§° Folder Structure
voice-to-chat-offline/
â”‚
â”œâ”€â”€ app.py                 # Flask app (routes)
â”œâ”€â”€ stt_whisper.py         # Whisper transcription
â”œâ”€â”€ tts_coqui.py           # Coqui TTS synthesis
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ Dockerfile             # Container config
â”œâ”€â”€ commands-to-run.txt    # Helper commands
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Web interface
â””â”€â”€ static/
    â”œâ”€â”€ script.js
    â”œâ”€â”€ style.css
    â”œâ”€â”€ uploads/
    â””â”€â”€ audio/

ğŸ§  Example API Workflow

/transcribe
POST .wav â†’ JSON text

{ "text": "hello world" }


/speak
POST JSON text â†’ generated output.wav

{ "audio_url": "/static/audio/output.wav" }

ğŸŒ Offline Behavior

ğŸ§± No external API calls â€” all inference happens locally.

ğŸ’¾ Models cached after first run.

ğŸ” Privacy-preserving â€” voice data never leaves your machine.

ğŸ”® Future Enhancements

Multilingual STT/TTS pairing

Voice selector dropdown in UI

Real-time transcription with Whisper streaming

Electron desktop packaging


ğŸ’¡ Acknowledgements

OpenAI Whisper

Coqui TTS

Flask

Mozilla TTS Models